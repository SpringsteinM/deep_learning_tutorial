{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOgAWZgwY6ZGlYP/fu1NOuY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SpringsteinM/deep_learning_tutorial/blob/main/summer_school_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training eines Deep Learning Models für Kunst Informationen\n",
        "\n",
        "In diesem Beispiel definieren wir ein neuronales Netz und optimieren es für die Vorhersage von kunstrelevanten Attributen. "
      ],
      "metadata": {
        "id": "6Lp0EUqV59Kl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Herunterladen des \"Painter by Numbers\" Kunstdatensatzes"
      ],
      "metadata": {
        "id": "xeF7WbE7qmQA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kaggle_key = \"KAGGLE\" #@param {type:\"string\"}\n"
      ],
      "metadata": {
        "id": "2reJLhNkzmkO",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGjqI4g_2qGs"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install open_clip_torch;\n",
        "!pip install kaggle;\n",
        "!pip install torchdata\n",
        "!pip install pytorch-lightning\n",
        "!pip install torchmetrics\n",
        "!mkdir ~/.kaggle -p;"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "kaggle_path = str(Path.home()/\".kaggle\"/\"kaggle.json\")\n",
        "with open(kaggle_path,\"w\") as f:\n",
        "  json.dump({\"username\":\"bhaallord\",\"key\":kaggle_key},f)\n",
        "!chmod 600 ~/.kaggle/kaggle.json;"
      ],
      "metadata": {
        "id": "kboMs5wnlct-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c painter-by-numbers -f train_1.zip\n",
        "!kaggle competitions download -c painter-by-numbers -f train_info.csv"
      ],
      "metadata": {
        "id": "9m2kerGwmNFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!unzip -o train_info.csv.zip"
      ],
      "metadata": {
        "id": "AU9KcSNfogPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definition aller notwendigen Funktionen und Klassen"
      ],
      "metadata": {
        "id": "ocWON3XRW_GS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import csv\n",
        "import re\n",
        "import imageio\n",
        "import torch\n",
        "import numpy as np\n",
        "from torchdata.datapipes.iter import FileLister, FileOpener\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms.functional import to_pil_image\n",
        "from torch.utils.data import DataLoader\n",
        "from PIL import Image\n",
        "\n",
        "train_t = transforms.Compose(\n",
        "    [\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "    ]\n",
        ")\n",
        "val_t = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "def preprocess_image(image):\n",
        "    return val_t(image)\n",
        "\n",
        "def preprocess_train_image(image):\n",
        "    return train_t(image)\n",
        "\n",
        "def read_info(info_path=\"train_info.csv\", data_field=\"style\"):\n",
        "    data = []\n",
        "    if data_field == \"style\":\n",
        "        data_field = 3\n",
        "    else:\n",
        "        data_field = 4\n",
        "    with open(info_path) as csvfile:\n",
        "        spamreader = csv.reader(csvfile)\n",
        "        next(spamreader)\n",
        "        for line in spamreader:\n",
        "            data.append((line[0], line[data_field]))\n",
        "    return data\n",
        "\n",
        "def generate_class_map(info_path=\"train_info.csv\", data_field=\"style\"):\n",
        "    data = []\n",
        "    class_map = {}\n",
        "    if data_field == \"style\":\n",
        "        data_field = 3\n",
        "    else:\n",
        "        data_field = 4\n",
        "    with open(info_path) as csvfile:\n",
        "        spamreader = csv.reader(csvfile)\n",
        "        next(spamreader)\n",
        "        for line in spamreader:\n",
        "            if line[data_field] not in class_map:\n",
        "                class_map[line[data_field]] = len(class_map)\n",
        "    return class_map\n",
        "\n",
        "def split_data(data, train_size=0.9):\n",
        "    return torch.utils.data.random_split(data, (int(0.9 * len(data)), len(data) - int(0.9 * len(data))))\n",
        "\n",
        "def generate_iterator(data_path=\"train_1.zip\", info_path=\"train_info.csv\", data_field=\"style\", set=\"val\"):\n",
        "    # load meta and split datasets\n",
        "    data = []\n",
        "    class_map = {}\n",
        "    if data_field == \"style\":\n",
        "        data_field = 3\n",
        "    else:\n",
        "        data_field = 4\n",
        "    with open(info_path) as csvfile:\n",
        "        spamreader = csv.reader(csvfile)\n",
        "        next(spamreader)\n",
        "        for line in spamreader:\n",
        "            if line[data_field] not in class_map:\n",
        "                class_map[line[data_field]] = len(class_map)\n",
        "            data.append((line[0], line[data_field]))\n",
        "    # dp = ImageFolder(str(path))\n",
        "    # model_dataset = WrapDataset(torchvision.datasets.ImageFolder(path))\n",
        "    train_data, val_data = torch.utils.data.random_split(data, \n",
        "      (int(0.9 * len(data)), len(data) - int(0.9 * len(data))), \n",
        "      generator=torch.Generator().manual_seed(42))\n",
        "    train_data = {k: v for k, v in train_data}\n",
        "    val_data = {k: v for k, v in val_data}\n",
        "    data = {k: v for k, v in data}\n",
        "    # building val and train pipe\n",
        "\n",
        "    dp = FileLister(\".\", \"*.zip\")\n",
        "    dp = FileOpener(dp, mode=\"b\")\n",
        "    dp = dp.load_from_zip()\n",
        "\n",
        "    def decode_data(d):\n",
        "      try:\n",
        "        filename = d[0].split(\"/\")[-1]\n",
        "        label = data.get(filename)\n",
        "        label_id = class_map.get(label)\n",
        "        return {\"filename\": filename, \"label\": label, \"label_id\": label_id, \"image_data\": d[1]}\n",
        "      except:\n",
        "        return None\n",
        "\n",
        "    dp = dp.map(decode_data)\n",
        "    if set==\"val\":\n",
        "      dp = dp.filter(lambda d: d[\"filename\"] in val_data)\n",
        "    elif set==\"train\":\n",
        "      dp = dp.filter(lambda d: d[\"filename\"] in train_data)\n",
        "\n",
        "    def decode_image(d):\n",
        "      try:\n",
        "        filename = d[\"filename\"]\n",
        "        label = d[\"label\"]\n",
        "        label_id =  d[\"label_id\"]\n",
        "        image = imageio.imread(d[\"image_data\"])\n",
        "        if len(image.shape) == 2:\n",
        "          image = np.expand_dims(image, axis=-1)\n",
        "        if image.shape[2] != 3:\n",
        "          image = np.concatenate([image,image,image], axis=-1)\n",
        "        if image.shape[-1] != 3:\n",
        "          return None\n",
        "        return {\"filename\": filename, \"label\": label, \"label_id\": label_id, \"image\": image}\n",
        "      except:\n",
        "        return None\n",
        "\n",
        "    dp = dp.map(decode_image)\n",
        "\n",
        "    dp = dp.map(lambda x: {**x, \"image\": preprocess_image(to_pil_image(x[\"image\"]))})\n",
        "    \n",
        "    return dp\n",
        "\n",
        "def generate_dataloaders(data_path=\"train_1.zip\", info_path=\"train_info.csv\", data_field=\"style\"):\n",
        "    # load meta and split datasets\n",
        "    data = []\n",
        "    class_map = {}\n",
        "    if data_field == \"style\":\n",
        "        data_field = 3\n",
        "    else:\n",
        "        data_field = 4\n",
        "    with open(info_path) as csvfile:\n",
        "        spamreader = csv.reader(csvfile)\n",
        "        next(spamreader)\n",
        "        for line in spamreader:\n",
        "            if line[data_field] not in class_map:\n",
        "                class_map[line[data_field]] = len(class_map)\n",
        "            data.append((line[0], line[data_field]))\n",
        "    # dp = ImageFolder(str(path))\n",
        "    # model_dataset = WrapDataset(torchvision.datasets.ImageFolder(path))\n",
        "    train_data, val_data = torch.utils.data.random_split(data, \n",
        "      (int(0.9 * len(data)), len(data) - int(0.9 * len(data))), \n",
        "      generator=torch.Generator().manual_seed(42))\n",
        "    train_data = {k: v for k, v in train_data}\n",
        "    val_data = {k: v for k, v in val_data}\n",
        "    data = {k: v for k, v in data}\n",
        "    # building val and train pipe\n",
        "\n",
        "    dp = FileLister(\".\", \"*.zip\")\n",
        "    dp = FileOpener(dp, mode=\"b\")\n",
        "    dp = dp.load_from_zip()\n",
        "    dp = dp.shuffle(buffer_size=128)\n",
        "\n",
        "\n",
        "    def decode_data(d):\n",
        "      try:\n",
        "        filename = d[0].split(\"/\")[-1]\n",
        "        label = data.get(filename)\n",
        "        label_id = class_map.get(label)\n",
        "        return {\"filename\": filename, \"label\": label, \"label_id\": label_id, \"image_data\": d[1]}\n",
        "      except:\n",
        "        return None\n",
        "\n",
        "    dp = dp.map(decode_data)\n",
        "    val_dp = dp.filter(lambda d: d[\"filename\"] in val_data)\n",
        "    train_dp = dp.filter(lambda d: d[\"filename\"] in train_data)\n",
        "\n",
        "    def decode_image(d):\n",
        "      try:\n",
        "        filename = d[\"filename\"]\n",
        "        label = d[\"label\"]\n",
        "        label_id =  d[\"label_id\"]\n",
        "        image = imageio.imread(d[\"image_data\"])\n",
        "        if len(image.shape) == 2:\n",
        "          image = np.expand_dims(image, axis=-1)\n",
        "        if image.shape[2] != 3:\n",
        "          image = np.concatenate([image,image,image], axis=-1)\n",
        "        if image.shape[-1] != 3:\n",
        "          return None\n",
        "        return {\"filename\": filename, \"label\": label, \"label_id\": label_id, \"image\": image}\n",
        "      except:\n",
        "        return None\n",
        "\n",
        "    val_dp = val_dp.map(decode_image)\n",
        "    train_dp = train_dp.map(decode_image)\n",
        "\n",
        "    val_dp = val_dp.filter(lambda x: x is not None)\n",
        "    train_dp = train_dp.filter(lambda x: x is not None)\n",
        "\n",
        "    train_dp = train_dp.map(lambda x: {**x, \"image\": preprocess_train_image(to_pil_image(x[\"image\"]))})\n",
        "    val_dp = val_dp.map(lambda x: {**x, \"image\": preprocess_image(to_pil_image(x[\"image\"]))})\n",
        "    \n",
        "    return DataLoader(train_dp, batch_size=64, num_workers=1), DataLoader(val_dp, batch_size=64, num_workers=1)\n",
        "\n",
        "def show_image_grid(images, labels=None):\n",
        "  plt.rcParams['figure.figsize'] = [18, 5]\n",
        "  image_grid = torchvision.utils.make_grid(images,nrow=4).numpy().transpose((1, 2, 0))\n",
        "\n",
        "  mean = np.array([0.485, 0.456, 0.406])\n",
        "  std = np.array([0.229, 0.224, 0.225])\n",
        "  image_grid = std * image_grid + mean\n",
        "  image_grid = np.clip(image_grid, 0, 1)\n",
        "\n",
        "  plt.imshow(image_grid)\n",
        "  if labels is not None:\n",
        "      plt.title(labels)"
      ],
      "metadata": {
        "id": "2diGjzo_W_Uz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Erkundung der vorhandenen Daten"
      ],
      "metadata": {
        "id": "fBh2sYeHvflD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_type = \"genre\" #@param [\"style\", \"genre\"]\n",
        "seed = 38 #@param {type:\"slider\", min:0, max:100, step:1}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "YIQIyi5ivoxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torchvision\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "pl.utilities.seed.seed_everything(seed)\n",
        "\n",
        "class_map = generate_class_map(data_field=label_type)\n",
        "class_map_inv = {v:k for k,v in class_map.items()}\n",
        "\n",
        "image_generator = iter(generate_iterator(data_field=label_type))\n",
        "images = []\n",
        "labels = []\n",
        "for x in range(8):\n",
        "  data = next(image_generator)\n",
        "  images.append(data[\"image\"])\n",
        "  labels.append(data[\"label\"])\n",
        "show_image_grid(images, labels)"
      ],
      "metadata": {
        "id": "Z3HNkcuvUQS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definition der Trainingsfunktion\n",
        "\n",
        "Diese Funktion übernimmt das Training für uns. Die Bilder und deren Label (Batch) werden aus unserer Datenpipeline geholt und für die Optimierung verwendet.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "W-_Nedj249g2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "from IPython import display\n",
        "from torch import autocast\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "def train_model(model, criterion, optimizer, scheduler, train_loader, val_loader, num_epochs=25, max_iter = 200):\n",
        "\n",
        "    since = time.time()\n",
        "\n",
        "\n",
        "    steps = []\n",
        "    losses = []\n",
        "    accuracies = []\n",
        "\n",
        "    global_step = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        dataloaders = {\n",
        "            'train':train_loader,\n",
        "            'val':val_loader\n",
        "        }\n",
        "        \n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train']:\n",
        "\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "            sample_count = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for batch in dataloaders[phase]:\n",
        "                inputs = batch[\"image\"].to(device)\n",
        "                labels = batch[\"label_id\"].to(device)\n",
        "\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    with autocast(\"cuda\"):\n",
        "\n",
        "                      outputs = model(inputs)\n",
        "                      _, preds = torch.max(outputs, 1)\n",
        "                      loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "                sample_count += labels.shape[0]\n",
        "\n",
        "                steps.append(global_step)\n",
        "                losses.append((loss.item()))\n",
        "                accuracies.append((torch.sum(preds == labels.data)/inputs.size(0)).cpu().detach().numpy())\n",
        "\n",
        "                if phase == 'train':\n",
        "                  # print(f'Epoch {epoch}/{num_epochs - 1} Step {global_step} Phase {phase}')\n",
        "                  fig, axs = plt.subplots(2, 1)\n",
        "                  axs[0].plot(steps,losses, color=\"r\") \n",
        "                  axs[0].set_xlabel('time')\n",
        "                  axs[0].set_ylabel('loss')\n",
        "                  axs[1].plot(steps,accuracies,  color=\"b\")    \n",
        "                  axs[1].set_xlabel('time')\n",
        "                  axs[1].set_ylabel('accuracy')\n",
        "                  display.clear_output(wait=True)\n",
        "                  display.display(plt.gcf())\n",
        "\n",
        "\n",
        "                  global_step+=1\n",
        "                \n",
        "                if max_iter and global_step > max_iter:\n",
        "                  return \n",
        "\n",
        "\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / sample_count\n",
        "            epoch_acc = running_corrects.double() / sample_count\n",
        "\n",
        "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "\n",
        "\n",
        "    display.clear_output(wait=True)\n",
        "    fig, axs = plt.subplots(2, 1)\n",
        "    axs[0].plot(steps,losses, color=\"r\") \n",
        "    axs[0].set_xlabel('time')\n",
        "    axs[0].set_ylabel('loss')\n",
        "    axs[1].plot(steps,accuracies,  color=\"b\")    \n",
        "    axs[1].set_xlabel('time')\n",
        "    axs[1].set_ylabel('accuracy')\n",
        "    return model"
      ],
      "metadata": {
        "id": "7EM_kuuX5AUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definition aller notwendigen Komponenten\n",
        "\n",
        "Hier definieren wir alle wichtigen Komponenten unseres Trainingsprozesses, die Folgendes umfassen:\n",
        "- Ein neuronales Modell, das ein Bild als Eingabe erhält und die Klassenwahrscheinlichkeit für jede einzelne Klasse liefert\n",
        "-  Ein Optimierungsverfahren, das festlegt, wie die Differenzen zwischen der Vorhersage und dem Ziel verringert werden sollen\n",
        "- Ein Optimierungsziel, das definiert, was wir zu erreichen versuchen\n",
        "- (optional) Eine Lernrate, die bestimmt, wie schnell wir etwas lernen\n",
        "\n"
      ],
      "metadata": {
        "id": "jKISSXf35XQv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torchvision import datasets, models, transforms\n",
        "\n",
        "model_ft = models.resnet18(pretrained=True)\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "# Here the size of each output sample is set to num classes.\n",
        "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
        "model_ft.fc = nn.Linear(num_ftrs, len(class_map))\n",
        "\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ],
      "metadata": {
        "id": "7rqacbcp5CZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluierung des neuen Modells\n"
      ],
      "metadata": {
        "id": "wwY6K58T7iqI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_generator = iter(generate_iterator(data_field=label_type))\n",
        "for x in range(8):\n",
        "  data = next(image_generator)\n",
        "  prediction = torch.nn.functional.softmax(model_ft(data[\"image\"].to(device).unsqueeze(0)), dim=-1).squeeze()\n",
        "  prediction = prediction.cpu().detach().numpy()\n",
        "  top_5 = np.argpartition(prediction, -5)[-5:]\n",
        "\n",
        "  \n",
        "  labels = [class_map_inv[x] for x in top_5]\n",
        "  prob = prediction[top_5]\n",
        "\n",
        "  image = data[\"image\"].numpy().transpose((1, 2, 0))\n",
        "  mean = np.array([0.485, 0.456, 0.406])\n",
        "  std = np.array([0.229, 0.224, 0.225])\n",
        "  image = std * image + mean\n",
        "  image = np.clip(image, 0, 1)\n",
        "\n",
        "  fig, axs = plt.subplots(1, 2)\n",
        "  axs[0].barh(labels, prob)\n",
        "  axs[1].imshow(image)\n",
        "  "
      ],
      "metadata": {
        "id": "74JGV6cs7iEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training des neuen Modells"
      ],
      "metadata": {
        "id": "T9vkGqXR7nTt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader, val_loader = generate_dataloaders(data_field=label_type)\n",
        "trained_model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,train_loader, val_loader, num_epochs=1)"
      ],
      "metadata": {
        "id": "eYMjagtn72zZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluierung des trainierten Modells"
      ],
      "metadata": {
        "id": "O54IWVqJv_s1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_generator = iter(generate_iterator(data_field=label_type))\n",
        "for x in range(8):\n",
        "  data = next(image_generator)\n",
        "  prediction = torch.nn.functional.softmax(trained_model_ft(data[\"image\"].to(device).unsqueeze(0)), dim=-1).squeeze()\n",
        "  prediction = prediction.cpu().detach().numpy()\n",
        "  top_5 = np.argpartition(prediction, -5)[-5:]\n",
        "\n",
        "  \n",
        "  labels = [class_map_inv[x] for x in top_5]\n",
        "  prob = prediction[top_5]\n",
        "\n",
        "  image = data[\"image\"].numpy().transpose((1, 2, 0))\n",
        "  mean = np.array([0.485, 0.456, 0.406])\n",
        "  std = np.array([0.229, 0.224, 0.225])\n",
        "  image = std * image + mean\n",
        "  image = np.clip(image, 0, 1)\n",
        "\n",
        "  fig, axs = plt.subplots(1, 2)\n",
        "  axs[1].imshow(image)\n",
        "  axs[0].barh(labels, prob)"
      ],
      "metadata": {
        "id": "FmDCbQQVAG1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchmetrics import ConfusionMatrix\n",
        "\n",
        "def eval(model,  val_loader, num_classes=2):\n",
        "\n",
        "    model.eval()   # Set model to evaluate mode\n",
        "\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    sample_count = 0\n",
        "\n",
        "    confmat = ConfusionMatrix(num_classes=num_classes)\n",
        "    # Iterate over data.\n",
        "    for batch in val_loader:\n",
        "        inputs = batch[\"image\"].to(device)\n",
        "        labels = batch[\"label_id\"].to(device)\n",
        "\n",
        "\n",
        "        with autocast(\"cuda\"):\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            confmat(preds.cpu(), labels.cpu())\n",
        "        \n",
        "        # statistics\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "        sample_count += labels.shape[0]\n",
        "\n",
        "\n",
        "        epoch_acc = running_corrects.double() / sample_count\n",
        "\n",
        "    \n",
        "    return confmat.compute(), epoch_acc\n",
        "  \n",
        "conf_matrix, acc = eval(trained_model_ft, val_loader, len(class_map))\n",
        "print(f\"Test ACC {acc}\")"
      ],
      "metadata": {
        "id": "SJWH_ioyzmtc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "df_cm = pd.DataFrame(conf_matrix.numpy()[:40,:40], index = [i for i in class_map.keys()][:40],\n",
        "                  columns = [i for i in class_map.keys()][:40])\n",
        "plt.figure(figsize = (15,15))\n",
        "sn.heatmap(df_cm, annot=True)"
      ],
      "metadata": {
        "id": "2oCL_f1g18pV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Jetzt können wir das Modell mit unseren eigenen Daten validieren"
      ],
      "metadata": {
        "id": "cAlnu05uO9AB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "id": "_f6RYEG_PRRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k, v in uploaded.items():\n",
        "  print(imageio.imread(v)[...,0:3].shape)\n",
        "  image = preprocess_image(to_pil_image(imageio.imread(v)[...,0:3]))\n",
        "  prediction = torch.nn.functional.softmax(trained_model_ft(image.to(device).unsqueeze(0)), dim=-1).squeeze()\n",
        "  prediction = prediction.cpu().detach().numpy()\n",
        "  top_5 = np.argpartition(prediction, -5)[-5:]\n",
        "\n",
        "  \n",
        "  labels = [class_map_inv[x] for x in top_5]\n",
        "  prob = prediction[top_5]\n",
        "\n",
        "  image = image.numpy().transpose((1, 2, 0))\n",
        "  mean = np.array([0.485, 0.456, 0.406])\n",
        "  std = np.array([0.229, 0.224, 0.225])\n",
        "  image = std * image + mean\n",
        "  image = np.clip(image, 0, 1)\n",
        "\n",
        "  fig, axs = plt.subplots(1, 2)\n",
        "  axs[1].imshow(image)\n",
        "  axs[0].barh(labels, prob)"
      ],
      "metadata": {
        "id": "ALpVcTGmPS3x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}